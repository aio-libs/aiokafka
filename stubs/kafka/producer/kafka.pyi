from kafka.client_async import KafkaClient as KafkaClient
from kafka.codec import has_gzip as has_gzip, has_lz4 as has_lz4, has_snappy as has_snappy
from kafka.metrics import MetricConfig as MetricConfig, Metrics as Metrics
from kafka.partitioner.default import DefaultPartitioner as DefaultPartitioner
from kafka.producer.future import FutureProduceResult as FutureProduceResult, FutureRecordMetadata as FutureRecordMetadata
from kafka.producer.record_accumulator import AtomicInteger as AtomicInteger, RecordAccumulator as RecordAccumulator
from kafka.producer.sender import Sender as Sender
from kafka.record.default_records import DefaultRecordBatchBuilder as DefaultRecordBatchBuilder
from kafka.record.legacy_records import LegacyRecordBatchBuilder as LegacyRecordBatchBuilder
from kafka.serializer import Serializer as Serializer
from kafka.structs import TopicPartition as TopicPartition
from typing import Any, Optional

log: Any
PRODUCER_CLIENT_ID_SEQUENCE: Any

class KafkaProducer:
    DEFAULT_CONFIG: Any = ...
    config: Any = ...
    def __init__(self, **configs: Any) -> None: ...
    def bootstrap_connected(self): ...
    def __del__(self) -> None: ...
    def close(self, timeout: Optional[Any] = ...) -> None: ...
    def partitions_for(self, topic: Any): ...
    def send(self, topic: Any, value: Optional[Any] = ..., key: Optional[Any] = ..., headers: Optional[Any] = ..., partition: Optional[Any] = ..., timestamp_ms: Optional[Any] = ...): ...
    def flush(self, timeout: Optional[Any] = ...) -> None: ...
    def metrics(self, raw: bool = ...): ...
